{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization\n",
    "- Summarize S-1 raw filings\n",
    "- Extract keywords\n",
    "- Batch process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Void\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "#core\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "\n",
    "#NLP\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from gensim.summarization import summarize\n",
    "from gensim.summarization import keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize IPO S-1 Filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load previous progress\n",
    "df = pd.read_csv('2 sentiment analysis.csv', index_col='Symbol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    for i in range(10):\n",
    "        print(x**i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_and_extract_keywords(x):\n",
    "    '''\n",
    "    x -- symbol\n",
    "    '''\n",
    "    #print(x)\n",
    "\n",
    "    #check if exists\n",
    "    #if Path(\"./Summary/\" + x + \".txt\").is_file() and Path(\"./Keywords/\" + x + \".txt\").is_file():\n",
    "    #    print(x + ' data already exists, skipping...')\n",
    "    #    return\n",
    "        \n",
    "    #read S-1\n",
    "    with open(\"./Data/\" + x + \".htm\", \"r\", encoding=\"utf-8\") as f:\n",
    "        html = f.read()\n",
    "        soup = BeautifulSoup(html,\"html5lib\")\n",
    "        text = soup.get_text(strip=True)\n",
    "\n",
    "        #summary and keywords\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        summary = summarize(text, ratio=0.01)\n",
    "        words = keywords(text, ratio=0.01)\n",
    "        \n",
    "        #write summary\n",
    "        with open(\"./Summary/\" + x + \".txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(summary)\n",
    "\n",
    "        #write keywords\n",
    "        with open(\"./Keywords/\" + x + \".txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            #lemmatize\n",
    "            lemmatized_keywords = []\n",
    "\n",
    "            for w in word_tokenize(words):\n",
    "                lemmatized_keywords.append(lemmatizer.lemmatize(w))\n",
    "\n",
    "            lemmatized_keywords = list(set(lemmatized_keywords))\n",
    "\n",
    "            #write\n",
    "            for k in lemmatized_keywords:\n",
    "                f.write('%s\\n' % k)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with Pool(4) as p:\n",
    "    p.map(summarize_and_extract_keywords, df.index[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "( 1 / 696 ) AACC\n",
      "AACC data already exists, skipping...\n",
      "\n",
      "( 2 / 696 ) AAT\n",
      "AAT data already exists, skipping...\n",
      "\n",
      "( 3 / 696 ) ABR\n",
      "ABR \n",
      "\n",
      "( 4 / 696 ) ABTX\n",
      "\n",
      "( 5 / 696 ) ACAD\n",
      "\n",
      "( 6 / 696 ) ACFC\n",
      "\n",
      "( 7 / 696 ) ACIA\n",
      "\n",
      "( 8 / 696 ) ACMR\n",
      "\n",
      "( 9 / 696 ) ACOR\n",
      "\n",
      "( 10 / 696 ) ACRX\n",
      "\n",
      "( 11 / 696 ) ACUS\n",
      "\n",
      "( 12 / 696 ) ADMS\n",
      "\n",
      "( 13 / 696 ) ADOM\n",
      "\n",
      "( 14 / 696 ) ADRO\n",
      "\n",
      "( 15 / 696 ) ADSW\n",
      "\n",
      "( 16 / 696 ) ADT\n",
      "\n",
      "( 17 / 696 ) ADUS\n",
      "\n",
      "( 18 / 696 ) AEL\n",
      "\n",
      "( 19 / 696 ) AERI\n",
      "\n",
      "( 20 / 696 ) AFFY\n",
      "\n",
      "( 21 / 696 ) AFH\n",
      "\n",
      "( 22 / 696 ) AIMC\n",
      "\n",
      "( 23 / 696 ) AIMT\n",
      "\n",
      "( 24 / 696 ) AIZ\n",
      "AIZ \n",
      "\n",
      "( 25 / 696 ) AJX\n",
      "\n",
      "( 26 / 696 ) AKAO\n",
      "\n",
      "( 27 / 696 ) AKBA\n",
      "\n",
      "( 28 / 696 ) AKER\n",
      "\n",
      "( 29 / 696 ) AL\n",
      "\n",
      "( 30 / 696 ) ALDR\n",
      "\n",
      "( 31 / 696 ) ALDX\n",
      "\n",
      "( 32 / 696 ) ALGT\n",
      "\n",
      "( 33 / 696 ) ALRM\n",
      "\n",
      "( 34 / 696 ) ALRN\n",
      "\n",
      "( 35 / 696 ) ALSN\n",
      "\n",
      "( 36 / 696 ) AM\n",
      "\n",
      "( 37 / 696 ) AMBA\n",
      "\n",
      "( 38 / 696 ) AMGP\n",
      "\n",
      "( 39 / 696 ) ANAB\n",
      "\n",
      "( 40 / 696 ) ANET\n",
      "\n",
      "( 41 / 696 ) ANGI\n",
      "\n",
      "( 42 / 696 ) ANTH\n",
      "\n",
      "( 43 / 696 ) APAM\n",
      "\n",
      "( 44 / 696 ) APEI\n",
      "\n",
      "( 45 / 696 ) APKT\n",
      "\n",
      "( 46 / 696 ) APO\n",
      "APO \n",
      "\n",
      "( 47 / 696 ) APPF\n",
      "\n",
      "( 48 / 696 ) APPN\n",
      "\n",
      "( 49 / 696 ) APRN\n",
      "\n",
      "( 50 / 696 ) ARMK\n",
      "\n",
      "( 51 / 696 ) ARMO\n",
      "\n",
      "( 52 / 696 ) ARYX\n",
      "\n",
      "( 53 / 696 ) ASV\n",
      "\n",
      "( 54 / 696 ) ATNX\n",
      "\n",
      "( 55 / 696 ) ATUS\n",
      "\n",
      "( 56 / 696 ) ATXI\n",
      "\n",
      "( 57 / 696 ) AUTH\n",
      "\n",
      "( 58 / 696 ) AVAV\n",
      "\n",
      "( 59 / 696 ) AVEO\n",
      "\n",
      "( 60 / 696 ) AVGR\n",
      "\n",
      "( 61 / 696 ) AYX\n",
      "\n",
      "( 62 / 696 ) BAS\n",
      "\n",
      "( 63 / 696 ) BBGI\n",
      "\n",
      "( 64 / 696 ) BBRG\n",
      "\n",
      "( 65 / 696 ) BBW\n",
      "\n",
      "( 66 / 696 ) BCC\n",
      "\n",
      "( 67 / 696 ) BCEI\n",
      "\n",
      "( 68 / 696 ) BCOV\n",
      "\n",
      "( 69 / 696 ) BCRH\n",
      "\n",
      "( 70 / 696 ) BEAT\n",
      "\n",
      "( 71 / 696 ) BECN\n",
      "\n",
      "( 72 / 696 ) BERY\n",
      "\n",
      "( 73 / 696 ) BFAM\n",
      "\n",
      "( 74 / 696 ) BFED\n",
      "\n",
      "( 75 / 696 ) BGFV\n",
      "\n",
      "( 76 / 696 ) BGMD\n",
      "\n",
      "( 77 / 696 ) BGNE\n",
      "\n",
      "( 78 / 696 ) BHVN\n",
      "\n",
      "( 79 / 696 ) BIOC\n",
      "\n",
      "( 80 / 696 ) BKD\n",
      "BKD \n",
      "\n",
      "( 81 / 696 ) BKU\n",
      "\n",
      "( 82 / 696 ) BL\n",
      "\n",
      "( 83 / 696 ) BLCM\n",
      "\n",
      "( 84 / 696 ) BLMN\n",
      "\n",
      "( 85 / 696 ) BLPH\n",
      "\n",
      "( 86 / 696 ) BMTI\n",
      "\n",
      "( 87 / 696 ) BNCL\n"
     ]
    }
   ],
   "source": [
    "#batch process\n",
    "counter = 0\n",
    "\n",
    "for x in df.index:\n",
    "    try:\n",
    "        counter += 1\n",
    "        print('\\n( ' + str(counter) + ' / ' + str(df.shape[0]) + ' ) ' + str(x))\n",
    "\n",
    "        #check if exists\n",
    "        if Path(\"./Summary/\" + x + \".txt\").is_file() and Path(\"./Keywords/\" + x + \".txt\").is_file():\n",
    "            print(x + ' data already exists, skipping...')\n",
    "            continue\n",
    "\n",
    "        #summarization and keywords\n",
    "        summarize_and_extract_keywords(x)\n",
    "    except Exception as e:\n",
    "        print(x, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
